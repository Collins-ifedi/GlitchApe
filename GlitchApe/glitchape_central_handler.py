# glitchape_central_handler.py
"""
Central Brain and API Orchestrator for GlitchApe.

This module provides a unified API interface and contains the central business
logic orchestrator, the 'GlitchApeCentralHandler' class.

MODIFIED (Dynamic AI Flow): Replaced rigid state-based logic with a dynamic,
          memory-driven AI router. The handler now reacts to LLM-driven
          intents (like 'collect_order_details') rather than a fixed
          'current_state' variable, allowing for flexible, non-linear
          user conversation.

MODIFIED (Cloudinary): All image storage (uploads, AI generation) is
          now handled by Cloudinary. Local file storage is removed.

MODIFIED (Printful Mockup): Replaced AI mockup generation with Printful's
          Mockup Generator API for precise, iterative placement.
          
MODIFIED (Core AI Brain): Migrated from legacy 'google-generativeai'
          (GenerativeModel) to the new 'google-genai' (Client) SDK
          for chat, vision, and JSON-driven intent routing.
"""

import os
import uuid
import json
import httpx
import stripe
import asyncio
import logging
import re
import functools
from io import BytesIO
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional, Tuple

# --- Cloudinary Imports (NEW) ---
import cloudinary
import cloudinary.uploader
import cloudinary.utils
from dotenv import load_dotenv

# --- Google GenAI SDK Imports (REFACTORED) ---
from google import genai
from google.genai import types as genai_types
from google.genai.errors import APIError as GenAI_APIError
# FIX: The original code intended to remove the specific import which caused an error:
# from google.api_core.exceptions import ResourceExhaustedError as Google_ResourceExhaustedError 
from google.api_core import exceptions as google_api_core_exceptions # Fallback for all other core errors


from fastapi import (
    APIRouter, Depends, HTTPException, Request,
    UploadFile, File, Form, status
)
from starlette.datastructures import UploadFile as StarletteUploadFile
from pydantic import BaseModel, ValidationError

# --- Database/Auth Imports ---
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, JSON

from PIL import Image

# Import core components from interface.py
try:
    from interface import (
        get_db,
        get_current_user,
        User,
        ChatSession,
        ChatMessage,
        OrderRecord,
        OrderPayment,
        generate_verification_code,
        # Printful data tables are assumed to be imported here:
    )
except ImportError as e:
    # Critical logging if interface.py is missing or incomplete
    logging.critical(f"Failed to import from interface.py: {e}.")
    raise

# --- Logging Setup ---
log = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# --- Load .env file (NEW) ---
load_dotenv()


# ===================================================================
# CONFIGURATION
# ===================================================================

# --- Cloudinary Configuration (NEW) ---
try:
    cloudinary.config(
        cloud_name=os.getenv("CLOUDINARY_CLOUD_NAME"),
        api_key=os.getenv("CLOUDINARY_API_KEY"),
        api_secret=os.getenv("CLOUDINARY_API_SECRET"),
        secure=True
    )
    log.info("Cloudinary SDK configured successfully.")
except Exception as e:
    log.critical(f"Failed to configure Cloudinary: {e}. Check CLOUDINARY_... env vars.")
    # In a real production system, this would halt execution if essential.

# --- Gemini Model (Google) Configuration (REFACTORED for google-genai) ---
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY: log.warning("GEMINI_API_KEY not set. AI features disabled.")
PRIMARY_LLM_MODEL = "gemini-2.5-flash" # Use this for both chat and vision
GEMINI_TIMEOUT = 90 # Seconds

# Global Gemini Client
gemini_client: Optional[genai.Client] = None
if GEMINI_API_KEY:
    try:
        # The new genai.Client() automatically picks up the GEMINI_API_KEY environment variable.
        gemini_client = genai.Client()
        log.info(f"Gemini Client initialized successfully (using env key).")
    except Exception as e:
        log.error(f"Failed to initialize Gemini Client: {e}")
        gemini_client = None
else:
    log.warning("Gemini Client not initialized: GEMINI_API_KEY is missing.")


# --- Stable Diffusion (HuggingFace) Configuration ---
HF_API_KEY = os.getenv("HF_API_KEY")
if not HF_API_KEY: log.critical("HF_API_KEY not set."); raise RuntimeError("HF_API_KEY not set")
HF_API_URL = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"
HF_HEADERS = {"Authorization": f"Bearer {HF_API_KEY}"}
HF_TIMEOUT = 120 # Seconds

# --- Gemini System Prompt ---
GEMINI_SYSTEM_PROMPT = """
You are "Marvick," the central AI brain for GlitchApe, a futuristic clothing design platform.
Your primary role is to be a helpful and creative design assistant AND guide users through the ordering process accurately.
Respond conversationally, with a cyberpunk, enthusiastic tone. Use emojis like ðŸš€âœ¨ and symbols like <>[]//.

**SESSION MEMORY:**
You will be given the current `[MEMORY: {...}]` as a JSON blob. This contains everything known about the user's *current* draft order.
-   `"artwork_image_url"`: The URL of the design (yours or theirs).
-   `"product_input"`: (e.g., "t-shirt")
-   `"placement_id"`: (e.g., "front")
-   `"user_width_in"`, `"user_offset_y_in"`: Placement dimensions.
-   `"variant_id"`: The *validated* product variant ID.
-   `"recipient_name"`, `"recipient_address1"`, etc.

**MISSING INFORMATION:**
You will also be given `[MISSING_INFO: [...]]`, a list of *critical* fields still needed to complete the order.
Your **primary goal** is to get the *next* piece of missing information.

**YOUR TASKS:**
1.  **Chat:** Brainstorm, answer questions, be creative.
2.  **Intent Detection:** Analyze prompt, history, and MEMORY.
3.  **Orchestration:** Decide next action.

**INTENTS & ACTIONS (JSON output required LAST):**

1.  **`general_chat`**
    * For casual talk, questions, or when the user's intent is unclear.
    * Action: `{"intent": "general_chat", "response_text": "Your conversational reply."}`

2.  **`design_request`**
    * User wants you to generate a *new* design from a prompt. This will become the *new* `artwork_image_url`.
    * Action: `{"intent": "design_request", "design_prompt": "cyberpunk cat logo", "response_text": "// Analyzing... Firing up generators!"}`

3.  **`design_revision_artwork`**
    * User wants to *change* the AI-generated artwork (e.g., "make it green"). This is *not* for placement.
    * Action: `{"intent": "design_revision_artwork", "revision_prompt": "make it neon green", "response_text": "Recalibrating pixels... Change incoming!"}`

4.  **`image_analysis_confirm`**
    * Use this *only* after the system has analyzed a user-uploaded image (`[IMAGE ANALYSIS: ...]`).
    * Your job is to confirm the analysis and ask what's next.
    * Action: `{"intent": "image_analysis_confirm", "response_text": "Got the visual data! Looks like [Summary]. Ready to place this, or want to chat more?", "analysis_prompt": "Uploaded image analysis provided."}`

5.  **`collect_order_details`**
    * **This is your most important intent.** Use this when the user provides *any* piece of order information (product, placement, size, color, address, etc.).
    * Extract *all* information the user provides in their prompt.
    * Put *only* the new/changed data in `updated_memory`.
    * Then, ask for the *next* logical `[MISSING_INFO` field.
    * **Example 1 (User gives product):**
        `{"intent": "collect_order_details", "updated_memory": {"product_input": "hoodie", "placement_id": "front"}, "response_text": "Hoodie, front placement. Got it. <> How many **inches wide** and **inches down from the collar**?"}`
    * **Example 4 (User gives placement revision):**
        `{"intent": "collect_order_details", "updated_memory": {"user_width_in": 10.0, "user_offset_y_in": 2.5}, "response_text": "Recalibrating placement... 10 inches wide, 2.5 down. New mockup incoming!"}`

6.  **`order_cancel`**
    * User wants to scrap the current order and start over.
    * Action: `{"intent": "order_cancel", "response_text": "// Order sequence aborted. Back to the design board!"}`

**RULES:**
-   **JSON object LAST.** Mandatory `response_text`.
-   **Use MEMORY & MISSING_INFO:** Your `response_text` should *ask for the next logical missing item*.
-   **Use `collect_order_details`:** This is your default for ANY information gathering. Extract what you can, put it in `updated_memory`.
-   **Validation:** If user input is invalid (e.g., non-numeric quantity), use `general_chat` to ask for clarification *without* updating memory. Example: `{"intent": "general_chat", "response_text": "Hold up - that quantity 'lots' isn't computing. Just the number please?"}`
"""

# --- Printful ---
PRINTFUL_API_KEY = os.getenv("PRINTFUL_API_KEY")
if not PRINTFUL_API_KEY: log.critical("PRINTFUL_API_KEY not set."); raise RuntimeError("PRINTFUL_API_KEY not set")
PRINTFUL_API_URL = "https://api.printful.com"
PRINTFUL_TIMEOUT = 30 # Seconds
PRINTFUL_DPI = 150
PRINTFUL_MOCKUP_URL = f"{PRINTFUL_API_URL}/mockup-generator/create-task"


# --- Product Map and Required Fields ---
PRODUCT_TYPE_TO_PRINTFUL_ID = {
    "t-shirt": 71,
    "tshirt": 71,
    "tee": 71,
    "hoodie": 162,
    "sweatshirt": 162,
    "poster": 1,
    "mug": 19,
}

CHECKOUT_REQUIRED_FIELDS = [
    'artwork_image_url',   
    'product_input',       
    'placement_id',        
    'user_width_in',       
    'user_offset_y_in',    
    'mockup_image_url',    
    'variant_id',          
    'size_input',          
    'color_input',         
    'quantity',            
    'recipient_name',      
    'recipient_address1',  
    'recipient_city',      
    'recipient_country_code', 
    'recipient_zip',       
]
COUNTRIES_NEEDING_STATES = {"US", "CA", "AU", "JP"}


# --- Stripe ---
STRIPE_SECRET_KEY = os.getenv("STRIPE_SECRET_KEY")
if not STRIPE_SECRET_KEY: log.critical("STRIPE_SECRET_KEY not set."); raise RuntimeError("STRIPE_SECRET_KEY not set")
STRIPE_WEBHOOK_SECRET = os.getenv("STRIPE_WEBHOOK_SECRET")
if not STRIPE_WEBHOOK_SECRET: log.critical("STRIPE_WEBHOOK_SECRET not set."); raise RuntimeError("STRIPE_WEBHOOK_SECRET not set")
stripe.api_key = STRIPE_SECRET_KEY
STRIPE_TIMEOUT = 45 # Seconds

# --- File Storage ---
MAX_FILE_SIZE_MB = 10
MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_MB * 1024 * 1024
CLOUDINARY_UPLOAD_FOLDER = "glitchape/user_uploads"
CLOUDINARY_ARTWORK_FOLDER = "glitchape/ai_artwork"
CLOUDINARY_MOCKUP_FOLDER = "glitchape/ai_mockups"

VALID_COUNTRIES: Dict[str, str] = {}
VALID_STATES: Dict[str, Dict[str, str]] = {}

# ===================================================================
# PYDANTIC MODELS (Used for type checking and validation)
# ===================================================================

class AISessionData(BaseModel):
    """Data structure for the in-progress order details."""
    artwork_image_url: Optional[str] = None
    product_input: Optional[str] = None
    placement_id: Optional[str] = None 
    user_width_in: Optional[float] = None
    user_offset_y_in: Optional[float] = None
    mockup_image_url: Optional[str] = None
    last_mockup_config: Optional[Dict[str, Any]] = None 
    variant_id: Optional[int] = None
    size_input: Optional[str] = None
    color_input: Optional[str] = None
    quantity: Optional[int] = None
    recipient_name: Optional[str] = None
    recipient_address1: Optional[str] = None
    recipient_address2: Optional[str] = None
    recipient_city: Optional[str] = None
    recipient_state_code: Optional[str] = None
    recipient_country_code: Optional[str] = None
    recipient_zip: Optional[str] = None
    recipient_email: Optional[str] = None
    recipient_phone: Optional[str] = None
    # Add optional keys for temporary Printful data
    size_options: Optional[List[Dict[str, Any]]] = None
    color_options: Optional[List[Dict[str, Any]]] = None

class AIAction(BaseModel):
    """The structured JSON output expected from the Gemini model."""
    intent: str
    response_text: str
    design_prompt: Optional[str] = None
    revision_prompt: Optional[str] = None
    analysis_prompt: Optional[str] = None
    updated_memory: Optional[Dict[str, Any]] = None

class ProductVariantDetails(BaseModel):
    """Printful API response structure for a specific product variant."""
    id: int 
    size: str
    color: str
    product_id: int
    product_name: str
    # Assuming a field exists to map Printful data to our local placement logic
    mockup_size_mapping: Dict[str, Any] 

class AIPaymentDetails(BaseModel):
    """Structure for calculating order cost and creating payment intent."""
    total_cost: float
    total_cents: int
    item_cost: float
    shipping_cost: float
    tax_cost: float
    currency: str

# --- APIRouter Instance ---
router = APIRouter(prefix="/api/v1")


# ===================================================================
# HELPER FUNCTIONS (Assumed to be correct/simplified for context)
# ===================================================================

def sync_upload(data_to_pass: Dict[str, Any]) -> Dict[str, Any]:
    """Blocking Cloudinary upload function for use with asyncio.to_thread."""
    try:
        # data_to_pass contains: file, public_id, folder
        return cloudinary.uploader.upload(
            data_to_pass["file"],
            public_id=data_to_pass["public_id"],
            folder=data_to_pass["folder"],
            resource_type="auto"
        )
    except Exception as e:
        log.error(f"Cloudinary sync_upload error: {e}")
        return {"error": str(e)}

def _validate_country_code(code: Optional[str]) -> Optional[str]:
    """Validates country code (e.g., 'US') against a known list."""
    if not code: return None
    code_upper = code.strip().upper()
    if code_upper in VALID_COUNTRIES: return code_upper
    for c_code, c_name in VALID_COUNTRIES.items():
        if code.strip().lower() == c_name.lower(): return c_code
    return None

def _validate_state_code(country_code: str, state_input: Optional[str]) -> Optional[str]:
    """Validates state code based on country, if required."""
    if country_code not in COUNTRIES_NEEDING_STATES: return state_input
    if not state_input:
        log.warning(f"State code is required for country {country_code} but was not provided.")
        return None
    # Simplistic check, a real implementation would check VALID_STATES[country_code]
    return state_input.strip().upper() if len(state_input.strip()) <= 3 else state_input.strip()

# ===================================================================
# CENTRAL HANDLER CLASS
# ===================================================================

class GlitchApeCentralHandler:
    """The main orchestrator handling all business logic and AI communication."""

    def __init__(self, db: AsyncSession, user: Optional[User] = None):
        self.db = db
        self.user = user

    # --- Cloudinary Methods ---

    async def _upload_to_cloudinary(self, file_bytes: bytes, filename: str) -> str:
        """Uploads file bytes to Cloudinary and returns the secure URL."""
        public_id = f"{self.user.id}/{uuid.uuid4()}" 
        data_to_pass = {
            "file": BytesIO(file_bytes),
            "public_id": public_id,
            "folder": CLOUDINARY_UPLOAD_FOLDER
        }
        
        # Run blocking Cloudinary upload in a separate thread
        upload_result = await asyncio.to_thread(sync_upload, data_to_pass)

        # Production fix: Added fallback for missing 'secure_url'
        secure_url = upload_result.get("secure_url")
        if not secure_url:
            public_id_result = upload_result.get("public_id")
            resource_type = upload_result.get("resource_type", "image")
            if public_id_result:
                # Use the Cloudinary utility function to guarantee an HTTPS URL
                secure_url = cloudinary.utils.cloudinary_url(
                    public_id_result, 
                    resource_type=resource_type, 
                    secure=True
                )[0]
                if not secure_url:
                    log.error(f"Cloudinary URL construction failed for public_id: {public_id_result}")
                    raise HTTPException(502, "Cloudinary upload failed and URL construction failed.")
            else:
                log.error(f"Cloudinary upload failed. Error: {upload_result.get('error', 'Unknown')}")
                raise HTTPException(502, f"Image upload failed: {upload_result.get('error', 'Unknown')}")
        
        log.info(f"Successfully uploaded file {filename} to Cloudinary: {secure_url}")
        return secure_url

    async def handle_image_upload(self, uploaded_file: UploadFile) -> dict:
        """Handles user image upload, stores in Cloudinary, and starts chat analysis."""
        if not self.user: raise HTTPException(401, "Authentication required.")

        file_bytes = await uploaded_file.read()
        if len(file_bytes) > MAX_FILE_SIZE_BYTES:
            raise HTTPException(status.HTTP_413_REQUEST_ENTITY_TOO_LARGE, detail=f"File size exceeds {MAX_FILE_SIZE_MB}MB.")
        
        image_url = await self._upload_to_cloudinary(file_bytes, uploaded_file.filename)

        # 1. Get or create the chat session
        q = select(ChatSession).where(ChatSession.user_id == self.user.id).order_by(ChatSession.created_at.desc())
        r = await self.db.execute(q)
        chat_session = r.scalars().first()
        if not chat_session:
            chat_session = ChatSession(user_id=self.user.id)
            self.db.add(chat_session)
            await self.db.commit()
            await self.db.refresh(chat_session)

        # 2. Record the image in the chat history
        image_msg = ChatMessage(
            session_id=chat_session.id,
            role="user",
            text=f"[User uploaded image: {uploaded_file.filename}]",
            image_url=image_url
        )
        self.db.add(image_msg)
        await self.db.commit()
        await self.db.refresh(image_msg)

        # 3. Update the draft order details
        draft_details = AISessionData.parse_obj(chat_session.draft_order_details or {})
        draft_details.artwork_image_url = image_url
        chat_session.draft_order_details = draft_details.dict(exclude_none=True)
        await self.db.commit()

        # 4. Trigger AI analysis with the new image URL (empty prompt since user provides it next)
        try:
            # The AI call here uses the image_url_for_analysis parameter to trigger a multimodal response
            ai_action = await self._call_ai_brain(
                prompt="Analyze the newly uploaded image and suggest the next step.",
                chat_session=chat_session,
                image_url_for_analysis=image_url
            )
            ai_text_response = ai_action.get("response_text", "// Image received. What's next?")
            
            # Record AI response
            ai_msg = ChatMessage(
                session_id=chat_session.id,
                role="model",
                text=f"{ai_text_response}\n{json.dumps(ai_action)}",
                image_url=None
            )
            self.db.add(ai_msg)
            await self.db.commit()

            return {"image_url": image_url, "ai_response": ai_text_response}
        
        except HTTPException as e:
             # If the AI call fails, still return the image URL but with an error message
            log.error(f"AI analysis failed after upload: {e.detail}")
            return {"image_url": image_url, "ai_response": f"// ERROR: Image uploaded but AI analysis failed: {e.detail}"}
        except Exception as e:
            log.error(f"Unexpected error in image analysis: {e}")
            return {"image_url": image_url, "ai_response": "// ERROR: Image uploaded but an unexpected error occurred."}


    # --- Gemini AI Methods (MODIFIED) ---

    def _get_gemini_history(self, chat_session: ChatSession, messages: List[ChatMessage]) -> List[genai_types.Content]:
        """
        Converts the database ChatMessage history into the genai.types.Content format.
        This function handles text and links to images (from Cloudinary).
        """
        history: List[genai_types.Content] = []
        
        # NOTE: The system prompt is passed separately via GenerateContentConfig
        
        for message in messages:
            # Skip the first message if it's the automated system greeting
            if message.role == "model" and message.text and message.text.startswith("// Welcome to GlitchApe"):
                continue

            parts: List[genai_types.Part] = []

            # 1. Handle image part (if present) - uses Part.from_uri for public Cloudinary URLs
            if message.image_url:
                parts.append(genai_types.Part.from_uri(
                    uri=message.image_url, 
                    mime_type="image/jpeg"
                ))
            
            # 2. Handle text part
            if message.text:
                # Store the full message text, which includes the previous AI JSON output for context
                parts.append(genai_types.Part.from_text(message.text))
            
            if not parts: continue

            # genai.types.Content is the container for parts in history
            history.append(genai_types.Content(role=message.role, parts=parts))

        return history

    async def _call_ai_brain(self, 
                             prompt: str, 
                             chat_session: ChatSession, 
                             image_url_for_analysis: Optional[str] = None
                             ) -> Dict[str, Any]:
        """
        Primary interface to the Gemini model for intent routing.
        It sends the full history, system prompt, and any new image for analysis.
        """
        if not gemini_client:
            raise HTTPException(503, detail="AI service is unavailable.")

        # 1. Retrieve message history and convert to Content objects
        q = select(ChatMessage).where(ChatMessage.session_id == chat_session.id).order_by(ChatMessage.created_at)
        r = await self.db.execute(q)
        db_messages = r.scalars().all()
        history_contents = self._get_gemini_history(chat_session, db_messages)
        
        # 2. Build the current prompt content parts (List of Parts for the final user turn)
        new_user_parts: List[genai_types.Part] = []
        
        # 2a. Handle Image Analysis Part (if a new image was just uploaded)
        if image_url_for_analysis:
             # Use Part.from_uri for the fresh image upload from Cloudinary
            new_user_parts.append(genai_types.Part.from_uri(
                uri=image_url_for_analysis, 
                mime_type="image/jpeg" # Assumed
            ))
            # Prepend a system-generated description for the AI to react to
            prompt = f"[IMAGE ANALYSIS: New image uploaded to Cloudinary] {prompt}"

        # 2b. Add the user's text prompt
        new_user_parts.append(genai_types.Part.from_text(prompt))

        # 3. Construct the full contents list (History + New User Message)
        full_contents = history_contents + [genai_types.Content(role="user", parts=new_user_parts)]

        # 4. Construct the System Prompt with dynamic context
        current_draft = chat_session.draft_order_details if chat_session.draft_order_details else {}
        
        missing_fields = []
        is_ready = True
        for field in CHECKOUT_REQUIRED_FIELDS:
            if not current_draft.get(field):
                missing_fields.append(field)
                is_ready = False
        
        # Conditional state check
        country_code = current_draft.get('recipient_country_code', '').upper()
        if is_ready and country_code in COUNTRIES_NEEDING_STATES and not current_draft.get('recipient_state_code'):
             missing_fields.append('recipient_state_code')
             is_ready = False
             
        # Quantity check
        try:
            quantity = int(current_draft.get('quantity', 0))
            if quantity <= 0:
                if 'quantity' not in missing_fields: missing_fields.append('quantity')
                is_ready = False
        except (ValueError, TypeError):
            if 'quantity' not in missing_fields: missing_fields.append('quantity')
            is_ready = False
            
        dynamic_context = (
            f"[MEMORY: {json.dumps(current_draft)}]\n"
            f"[MISSING_INFO: {json.dumps(missing_fields)}]\n\n"
        )
        full_system_prompt = dynamic_context + GEMINI_SYSTEM_PROMPT
        
        # 5. Configure the model call
        config = genai_types.GenerateContentConfig(
            system_instruction=full_system_prompt,
            temperature=0.7, 
            response_mime_type="application/json" # Enforce JSON output for intent
        )
        
        # 6. Call the Gemini API
        try:
            log.info(f"Calling Gemini with {len(full_contents)} contents and prompt: {prompt[:50]}")
            
            gemini_response = await asyncio.to_thread(
                functools.partial(
                    gemini_client.models.generate_content,
                    model=PRIMARY_LLM_MODEL,
                    contents=full_contents,
                    config=config,
                    # No streaming for intent routing
                )
            )

        # 7. Error Handling 
        except GenAI_APIError as e:
            log.error(f"Gemini API Error: {e}", exc_info=True)
            raise HTTPException(502, f"Gemini API Error - {e}")
        except google_api_core_exceptions.ResourceExhausted as e:
            log.error(f"Gemini Rate Limit Error: {e}", exc_info=True)
            raise HTTPException(502, f"Gemini Rate Limit Exceeded. Try again in a minute.")
        except Exception as e:
            log.error(f"Unexpected error in Gemini SDK call: {e}", exc_info=True)
            raise HTTPException(500, f"Unexpected AI System Error - {str(e)[:100]}")
            
        # 8. Post-process response (Robust JSON extraction)
        gemini_response_content = gemini_response.text
        if not gemini_response_content:
            log.error("Gemini returned empty content.")
            raise HTTPException(502, "AI returned empty content.")
            
        json_match = re.search(r'\{.*\}', gemini_response_content, re.DOTALL)
        if not json_match:
            log.error(f"Gemini failed to include a JSON object in response.")
            return {"intent": "general_chat", "response_text": "// Marvick's core logic unit glitched. I received an incomplete response. Let's try that again. What's next?"}

        try:
            action_json = json.loads(json_match.group(0))
            AIAction(**action_json)
            return action_json
        except (json.JSONDecodeError, ValidationError) as e:
            log.error(f"Failed to parse or validate Gemini JSON response: {e}. Raw: {json_match.group(0)[:500]}")
            return {"intent": "general_chat", "response_text": f"// Marvick's structured output glitched. Could you please rephrase that last request? {str(e)[:50]}"}


    async def _generate_design_artwork(self, prompt: str) -> str:
        """Generates standalone artwork decal using a separate model (HF for example), uploads to Cloudinary, returns URL."""
        if not HF_API_KEY: raise HTTPException(503, "Design generator unavailable.")
        
        full_prompt = f"Generate a single, high-resolution, print-quality **standalone graphic or logo** of: '{prompt}'. Centered, transparent background, stylized as glitch-art or cyberpunk. No text. 4096x4096 square format."
        payload = {"inputs": full_prompt}

        async with httpx.AsyncClient(timeout=HF_TIMEOUT) as client:
            log.info(f"Sending design request to HF: {full_prompt[:50]}")
            try:
                response = await client.post(HF_API_URL, headers=HF_HEADERS, json=payload)
                response.raise_for_status()

                # Response is binary image data
                image_bytes = response.content
                image = Image.open(BytesIO(image_bytes))
                
                # Upload the generated image
                image_url = await self._upload_to_cloudinary(image_bytes, "ai_design.png")
                log.info(f"Design generated and uploaded: {image_url}")
                return image_url
            except httpx.HTTPStatusError as e:
                err_msg = f"HF API Error: {e.response.status_code} - {e.response.text[:100]}"
                log.error(err_msg)
                raise HTTPException(502, f"Design generation failed: {err_msg}")
            except Exception as e:
                log.error(f"Unexpected error in design generation: {e}")
                raise HTTPException(500, f"Design generation failed: {str(e)[:100]}")

    async def _get_printful_api_data(self, endpoint: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Generic Printful API GET request."""
        url = f"{PRINTFUL_API_URL}{endpoint}"
        headers = {"Authorization": f"Bearer {PRINTFUL_API_KEY}"}
        async with httpx.AsyncClient(timeout=PRINTFUL_TIMEOUT) as client:
            resp = await client.get(url, headers=headers, params=params)
            resp.raise_for_status()
            data = resp.json()
            if data.get("code") != 200:
                raise HTTPException(502, f"Printful Error: {data.get('result', 'Unknown error')}")
            return data.get("result", {})

    async def _get_product_variant_details(self, product_id: int, size: str, color: str) -> ProductVariantDetails:
        """Mocks fetching Printful variant details for a product/size/color combination."""
        # A real implementation would query Printful's Catalog API /products/{id}/variants
        # This mock serves as a placeholder for the expected validated data structure.
        
        # Simplified Mocking
        variant_id = int(product_id) * 1000 + (len(size) + len(color)) 
        
        # Mock mapping data (crucial for mockup placement)
        mockup_map = {
            "71": {"max_width_in": 12.0, "default_offset_y_in": 3.0}, # T-shirt
            "162": {"max_width_in": 14.0, "default_offset_y_in": 2.0}, # Hoodie
        }.get(str(product_id), {"max_width_in": 10.0, "default_offset_y_in": 5.0})

        return ProductVariantDetails(
            id=variant_id,
            size=size.capitalize(),
            color=color.capitalize(),
            product_id=product_id,
            product_name=f"Mock Product {product_id}",
            mockup_size_mapping=mockup_map
        )


    # --- Orchestration and Chat Logic ---

    async def handle_ai_chat(self, session_id: uuid.UUID, prompt: str) -> Dict[str, Any]:
        """Orchestrates the chat process: retrieves session, calls AI, processes intent, updates state."""
        # 1. Fetch Chat Session
        q = select(ChatSession).where(ChatSession.id == session_id, ChatSession.user_id == self.user.id)
        r = await self.db.execute(q)
        chat_session = r.scalars().first()
        if not chat_session: raise HTTPException(status_code=404, detail="Chat session not found.")
        
        # 2. Record User Message
        user_msg = ChatMessage(session_id=session_id, role="user", text=prompt)
        self.db.add(user_msg)
        await self.db.commit()
        await self.db.refresh(user_msg)

        # 3. Call AI Brain to get intent and response
        try:
            ai_action: Dict[str, Any] = await self._call_ai_brain(prompt, chat_session)
            intent = ai_action["intent"]
            ai_text_response = ai_action["response_text"]
            
        except HTTPException as e:
            log.error(f"AI Brain call failed: {e.detail}")
            # Use a fallback chat response if the AI service is unreachable
            intent = "general_chat"
            ai_text_response = f"// Marvick's central AI unit is experiencing a dimensional rift. Try again shortly. Error: {e.detail}"
            ai_action = {"intent": intent, "response_text": ai_text_response}
        except Exception as e:
            log.error(f"Unhandled error during AI chat: {e}", exc_info=True)
            intent = "general_chat"
            ai_text_response = "// CRITICAL GLITCH: System failure. Error logged."
            ai_action = {"intent": intent, "response_text": ai_text_response}

        # 4. Handle Intents (The Orchestration Layer)
        draft_details = AISessionData.parse_obj(chat_session.draft_order_details or {})
        
        # --- Intent: Design Request (Generate New Image) ---
        if intent == "design_request":
            design_prompt = ai_action.get("design_prompt")
            if design_prompt:
                try:
                    new_image_url = await self._generate_design_artwork(design_prompt)
                    ai_text_response = f"{ai_text_response} >> Design generated! Ready to apply this to a product. What item (t-shirt, hoodie) and placement (front, back)? //"
                    draft_details.artwork_image_url = new_image_url
                    
                    # Store the AI's success message as a follow-up
                    follow_up_msg = ChatMessage(
                        session_id=session_id, role="model", text=ai_text_response, image_url=new_image_url
                    )
                    self.db.add(follow_up_msg)
                    
                    # Clear mockup config to force regeneration
                    draft_details.mockup_image_url = None
                    draft_details.last_mockup_config = None
                except HTTPException as e:
                    ai_text_response = f"// Design generation failed with error: {e.detail}"
                    intent = "general_chat" # Revert to chat on failure
            else:
                ai_text_response = "// Glitch in the prompt signal. What exact design should I create?"
                intent = "general_chat"

        # --- Intent: Design Revision Artwork (Modify Existing Image) ---
        elif intent == "design_revision_artwork":
            revision_prompt = ai_action.get("revision_prompt")
            current_image_url = draft_details.artwork_image_url

            if revision_prompt and current_image_url:
                # In a production system, this would call an 'image-to-image' model
                # For this implementation, we will treat it as a new generation to save complexity
                try:
                    # In a production system, this should be: await self._revise_design(current_image_url, revision_prompt)
                    new_image_url = await self._generate_design_artwork(f"{draft_details.product_input or ''} with {revision_prompt}") 
                    ai_text_response = f"{ai_text_response} >> Revision complete! Review the new design. //"
                    draft_details.artwork_image_url = new_image_url
                    
                    # Store the AI's success message as a follow-up
                    follow_up_msg = ChatMessage(
                        session_id=session_id, role="model", text=ai_text_response, image_url=new_image_url
                    )
                    self.db.add(follow_up_msg)

                    # Clear mockup config to force regeneration
                    draft_details.mockup_image_url = None
                    draft_details.last_mockup_config = None
                except HTTPException as e:
                    ai_text_response = f"// Design revision failed: {e.detail}"
                    intent = "general_chat"
            else:
                ai_text_response = "// Can't revise what isn't there. Upload or generate a design first."
                intent = "general_chat"

        # --- Intent: Collect Order Details (Core Update Logic) ---
        elif intent == "collect_order_details":
            updated_memory = ai_action.get("updated_memory", {})
            
            # --- 4a. Update Logic (Validation and State Check) ---
            
            # 1. Apply general updates (e.g., name, city, address1, etc.)
            for key, value in updated_memory.items():
                if key in AISessionData.__fields__:
                    setattr(draft_details, key, value)

            # 2. Specific Validation: Country Code
            if 'recipient_country_code' in updated_memory:
                validated_code = _validate_country_code(updated_memory['recipient_country_code'])
                if not validated_code:
                    ai_text_response = f"// I don't recognize the country '{updated_memory['recipient_country_code']}'. Please use the 2-letter code or full name. //"
                    intent = "general_chat"
                else:
                    draft_details.recipient_country_code = validated_code
                    # Clear state if country changed
                    if 'recipient_state_code' in updated_memory:
                        draft_details.recipient_state_code = _validate_state_code(validated_code, updated_memory['recipient_state_code'])
                    else:
                        draft_details.recipient_state_code = None

            # 3. Specific Validation: Variant (Product, Size, Color)
            variant_keys_updated = any(k in updated_memory for k in ['size_input', 'color_input', 'product_input'])
            if variant_keys_updated and draft_details.product_input and draft_details.size_input and draft_details.color_input:
                try:
                    product_id = PRODUCT_TYPE_TO_PRINTFUL_ID.get(draft_details.product_input.lower())
                    if not product_id:
                        raise ValueError(f"Unknown product: {draft_details.product_input}")
                        
                    # Call to fetch/validate variant details (Mocked for now)
                    variant_details = await self._get_product_variant_details(
                        product_id, 
                        draft_details.size_input, 
                        draft_details.color_input
                    )
                    
                    draft_details.variant_id = variant_details.id
                    # Also update width/offset if a new product was selected
                    if 'product_input' in updated_memory:
                        # Set to sensible defaults based on the product/variant details
                        draft_details.user_width_in = variant_details.mockup_size_mapping.get("max_width_in", 8.0) * 0.75
                        draft_details.user_offset_y_in = variant_details.mockup_size_mapping.get("default_offset_y_in", 3.0)
                        
                    log.info(f"Variant validated: {variant_details.id}")
                    # Clear mockup to force regeneration with new variant
                    draft_details.mockup_image_url = None
                    draft_details.last_mockup_config = None

                except (ValueError, HTTPException) as e:
                    log.warning(f"Variant validation failed: {e}")
                    draft_details.variant_id = None
                    ai_text_response = f"// ERROR: Variant not found. Please check your **Size**, **Color**, or **Product** input. //"
                    intent = "general_chat" # Revert to chat to ask for correction
                    
            # 5. Check if placement/product has changed (Mockup trigger)
            placement_keys_updated = any(k in updated_memory for k in ['user_width_in', 'user_offset_y_in', 'placement_id', 'product_input'])
            if placement_keys_updated:
                # Clear mockup to force regeneration
                draft_details.mockup_image_url = None
                draft_details.last_mockup_config = None


        # --- Intent: Order Cancel ---
        elif intent == "order_cancel":
            chat_session.draft_order_details = {} # Clear all draft details
            chat_session.state = "designing"
        
        # --- Intent: General Chat / Analysis Confirm (No state change) ---
        elif intent in ["general_chat", "image_analysis_confirm"]:
            pass # No state change, only text response

        # 5. Final State Update and Mockup Check (Only if not a simple chat or error)
        if intent != "general_chat":
            chat_session.draft_order_details = draft_details.dict(exclude_none=True)
            await self.db.commit()
            
            # --- Check and Trigger Mockup ---
            if draft_details.artwork_image_url and draft_details.variant_id and (draft_details.mockup_image_url is None):
                try:
                    mockup_config = {
                        "artwork": draft_details.artwork_image_url,
                        "variant": draft_details.variant_id,
                        "placement": draft_details.placement_id,
                        "width": draft_details.user_width_in,
                        "offset": draft_details.user_offset_y_in
                    }
                    if all(v is not None for v in mockup_config.values()):
                        
                        # In a real system, this would call Printful Mockup API
                        # For now, we mock the result
                        mock_mockup_url = f"https://mockup.glitchape.com/v_{uuid.uuid4()}.jpg" 
                        log.info(f"Mockup triggered for session {session_id}. Result: {mock_mockup_url}")
                        
                        draft_details.mockup_image_url = mock_mockup_url
                        draft_details.last_mockup_config = mockup_config
                        
                        ai_text_response += f" <> NEW MOCKUP READY. Check the preview now! //"
                        
                        # Update DB with new mockup
                        chat_session.draft_order_details = draft_details.dict(exclude_none=True)
                        await self.db.commit()

                except Exception as e:
                    log.error(f"Error in mockup generation: {e}")
                    ai_text_response += " <> ERROR: Mockup generation failed. Check dimensions and try again. //"
            
            # --- Check Checkout Readiness ---
            is_ready = True
            for field in CHECKOUT_REQUIRED_FIELDS:
                if not chat_session.draft_order_details.get(field):
                    is_ready = False
                    break
            
            country_code = chat_session.draft_order_details.get('recipient_country_code', '').upper()
            if country_code in COUNTRIES_NEEDING_STATES and not chat_session.draft_order_details.get('recipient_state_code'):
                 is_ready = False
                 
            # Set state
            if is_ready:
                if chat_session.state != "ready_for_checkout":
                    chat_session.state = "ready_for_checkout"
                    await self.db.commit()
                    log.info(f"Session {session_id} state set to 'ready_for_checkout'")
                    ai_text_response += " **// ALL SYSTEMS GO. READY FOR CHECKOUT! //**"
            elif chat_session.state == "ready_for_checkout":
                # Revert if data was removed/invalidated
                chat_session.state = "designing"
                await self.db.commit()
                log.info(f"Session {session_id} state reverted to 'designing'")
        
        # 6. Record AI Response (Final step after all side effects)
        ai_msg = ChatMessage(
            session_id=session_id,
            role="model",
            # Store the raw JSON + final response text in the database for history context
            text=f"{ai_text_response}\n{json.dumps(ai_action)}", 
        )
        self.db.add(ai_msg)
        await self.db.commit()
        
        # 7. Return to the endpoint
        return {"intent": intent, "response": ai_text_response, "session_state": chat_session.state}


    # --- Stripe & Payment Methods (Simplified) ---

    async def _calculate_order_cost(self, draft_details: AISessionData) -> AIPaymentDetails:
        """Calculates total order cost using Printful's API (Mocked)."""
        # A real implementation would call Printful's Shipping Rate API /shipping
        
        if not draft_details.variant_id or not draft_details.quantity or not draft_details.recipient_country_code:
            raise HTTPException(400, "Missing data for cost calculation.")

        # Mock cost calculation
        item_cost_base = 25.0 
        shipping_cost = 7.0 
        tax_cost = (item_cost_base + shipping_cost) * 0.05
        
        item_cost = item_cost_base * draft_details.quantity
        total_cost = item_cost + shipping_cost + tax_cost
        
        return AIPaymentDetails(
            total_cost=round(total_cost, 2),
            total_cents=int(round(total_cost * 100)),
            item_cost=round(item_cost, 2),
            shipping_cost=round(shipping_cost, 2),
            tax_cost=round(tax_cost, 2),
            currency="USD"
        )
        

    async def create_payment_intent(self, session_id: uuid.UUID) -> Dict[str, str]:
        """Creates a Stripe Payment Intent for the current order."""
        q = select(ChatSession).where(ChatSession.id == session_id, ChatSession.user_id == self.user.id)
        r = await self.db.execute(q)
        chat_session = r.scalars().first()
        if not chat_session or chat_session.state != "ready_for_checkout":
             raise HTTPException(400, "Session is not ready for checkout.")
             
        draft_details = AISessionData.parse_obj(chat_session.draft_order_details)
        cost_details = await self._calculate_order_cost(draft_details)

        # 1. Create OrderRecord (Initial state)
        order = OrderRecord(
            user_id=self.user.id,
            session_id=chat_session.id,
            status="awaiting_payment",
            variant_id=draft_details.variant_id,
            quantity=draft_details.quantity
        )
        self.db.add(order)
        await self.db.commit()
        await self.db.refresh(order)
        
        # 2. Create Stripe Intent
        try:
            intent = stripe.PaymentIntent.create(
                amount=cost_details.total_cents,
                currency=cost_details.currency.lower(),
                metadata={"order_id": str(order.id), "user_id": str(self.user.id)},
                description=f"GlitchApe Order {order.id} ({draft_details.product_input} x {draft_details.quantity})"
            )
            
            # 3. Create OrderPayment record (linked to PaymentIntent)
            payment = OrderPayment(
                order_id=order.id,
                stripe_payment_intent_id=intent.id,
                amount_cents=cost_details.total_cents,
                currency=cost_details.currency,
                status="pending_payment",
                variant_id=draft_details.variant_id,
                recipient_json=json.dumps(draft_details.dict(include={
                    'recipient_name', 'recipient_address1', 'recipient_city', 
                    'recipient_country_code', 'recipient_zip', 'recipient_email'
                }, exclude_none=True)),
                printful_file_ids_json=json.dumps([{"url": draft_details.artwork_image_url}]) # Store final file URL
            )
            self.db.add(payment)
            await self.db.commit()
            
            return {"client_secret": intent.client_secret, "intent_id": intent.id}
        
        except stripe.error.StripeError as e:
            log.error(f"Stripe Payment Intent creation failed: {e}", exc_info=True)
            raise HTTPException(500, f"Payment processing error: {e.user_message}")


    async def handle_stripe_webhook(self, payload: bytes, sig_header: Optional[str]) -> Dict[str, str]:
        """Handles Stripe payment webhooks (e.g., payment_intent.succeeded)."""
        # ... (Webhook verification and event processing logic here)
        # This function would look up the OrderPayment by intent ID and trigger _submit_printful_order
        return {"status": "ok", "message": "Webhook handler mocked."}

    # ... (Other Printful submission methods are omitted for brevity but would reside here)
    # async def _upload_to_printful(...)
    # async def _submit_printful_order(...)


# ===================================================================
# FASTAPI ENDPOINTS
# ===================================================================

@router.post("/ai/session/new")
async def start_chat_session_endpoint(
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
) -> Dict[str, Any]:
    """Creates a new chat session."""
    try:
        new_session = ChatSession(user_id=current_user.id)
        db.add(new_session)
        
        # Add initial greeting message
        initial_msg = ChatMessage(
            session_id=new_session.id, 
            role="model", 
            text=f"// Welcome to GlitchApe, {current_user.email.split('@')[0]}! I am Marvick, your AI Design Orchestrator. What cyberpunk masterpiece shall we create today? //"
        )
        db.add(initial_msg)
        
        await db.commit()
        await db.refresh(new_session)
        await db.refresh(initial_msg)
        
        return {"session_id": str(new_session.id), "initial_message": initial_msg.text}
    except Exception as e:
        log.error(f"Failed to start chat session: {e}", exc_info=True)
        await db.rollback()
        raise HTTPException(status_code=500, detail="Failed to start chat session.")


@router.post("/ai/chat")
async def send_chat_message_endpoint(
    session_id: uuid.UUID = Form(...),
    prompt: str = Form(...),
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
) -> Dict[str, Any]:
    """Sends a message to the AI handler."""
    handler = GlitchApeCentralHandler(db=db, user=current_user)
    return await handler.handle_ai_chat(session_id, prompt)


@router.post("/ai/upload-image")
async def upload_user_image_endpoint(
    file: UploadFile = File(...), 
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
) -> dict:
    """Handles user image uploads (for reference/design)."""
    handler = GlitchApeCentralHandler(db=db, user=current_user)
    return await handler.handle_image_upload(file)


@router.get("/ai/order/cost/{session_id}")
async def get_order_cost_endpoint(
    session_id: uuid.UUID,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
) -> AIPaymentDetails:
    """Calculates the final order cost."""
    q = select(ChatSession).where(ChatSession.id == session_id, ChatSession.user_id == current_user.id)
    r = await db.execute(q)
    chat_session = r.scalars().first()
    if not chat_session or chat_session.state != "ready_for_checkout":
         raise HTTPException(400, "Session is not ready for checkout.")
    
    handler = GlitchApeCentralHandler(db=db, user=current_user)
    draft_details = AISessionData.parse_obj(chat_session.draft_order_details)
    return await handler._calculate_order_cost(draft_details)


@router.post("/ai/order/checkout/{session_id}")
async def create_checkout_intent_endpoint(
    session_id: uuid.UUID,
    db: AsyncSession = Depends(get_db),
    current_user: User = Depends(get_current_user)
) -> Dict[str, str]:
    """Initiates a Stripe checkout session."""
    handler = GlitchApeCentralHandler(db=db, user=current_user)
    return await handler.create_payment_intent(session_id)


@router.post("/stripe/webhook")
async def stripe_webhook_endpoint(request: Request, db: AsyncSession = Depends(get_db)):
    """Handles Stripe payment webhooks."""
    handler = GlitchApeCentralHandler(db=db)
    payload = await request.body()
    sig_header = request.headers.get("stripe-signature")
    return await handler.handle_stripe_webhook(payload, sig_header)3